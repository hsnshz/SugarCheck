{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Algorithms Comparitive Analysis for prediction of A1C levels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries for Data Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Importing Libraries for Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Importing Libraries for Regression Models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Importing Libraries for Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../../../Dataset/a1c-estimation-dataset.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for null values\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle duplicates\n",
    "duplicate_rows = data[data.duplicated()]\n",
    "print(\"Number of duplicate rows: \", duplicate_rows.shape)\n",
    "\n",
    "data = data.drop_duplicates()\n",
    "duplicate_rows = data[data.duplicated()]\n",
    "print(\"Number of duplicate rows: \", duplicate_rows.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for data types\n",
    "data.info()\n",
    "\n",
    "# Coverting columns to lower case\n",
    "data.columns = map(str.lower, data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unneccessary values (0.00195%)\n",
    "data = data[data[\"gender\"] != \"Other\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the data\n",
    "data.describe().style.format(\"{:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution of class labels\n",
    "class_counts = data[\"diabetes\"].value_counts()\n",
    "colors = [\"teal\", \"skyblue\", \"coral\", \"gold\", \"lightcoral\"]\n",
    "\n",
    "# Create the pie chart\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(\n",
    "    class_counts,\n",
    "    labels=class_counts.index,\n",
    "    autopct=\"%1.1f%%\",\n",
    "    startangle=140,\n",
    "    colors=colors,\n",
    ")\n",
    "plt.axis(\"equal\")\n",
    "plt.title(\"Distribution of Class Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram for Age distribution\n",
    "plt.figure(figsize=(7, 4))\n",
    "sns.histplot(data[\"age\"], kde=True)\n",
    "plt.title(\"Age Distribution\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot for gender\n",
    "sns.countplot(x=\"gender\", data=data, palette=\"Set3\")\n",
    "plt.title(\"Gender Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution plot for BMI with color\n",
    "sns.displot(data[\"bmi\"], bins=30, color=\"teal\", kde=True)\n",
    "plt.title(\"BMI Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot blood glucose level vs Diabetes classification\n",
    "sns.boxplot(x=\"diabetes\", y=\"blood_glucose_level\", data=data, palette=\"magma\")\n",
    "plt.title(\"Blood Glucose Level vs Diabetes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot HbA1c level vs Diabetes classification\n",
    "sns.boxplot(x=\"diabetes\", y=\"hba1c_level\", data=data, palette=\"viridis\")\n",
    "plt.title(\"HbA1c level vs Diabetes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot for Blood Glucose Level vs. HbA1c Level\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=\"blood_glucose_level\", y=\"hba1c_level\", hue=\"diabetes\", data=data)\n",
    "plt.title(\"Blood Glucose Level vs. HbA1c Level\")\n",
    "plt.xlabel(\"Blood Glucose Level\")\n",
    "plt.ylabel(\"HbA1c Level\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary to map the existing categories to new ones\n",
    "smoking_mapping = {\n",
    "    \"never\": \"non-smoker\",\n",
    "    \"No Info\": \"non-smoker\",\n",
    "    \"current\": \"current\",\n",
    "    \"ever\": \"past_smoker\",\n",
    "    \"former\": \"past_smoker\",\n",
    "    \"not current\": \"past_smoker\",\n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'smoking_history' column\n",
    "data[\"smoking_history\"] = data[\"smoking_history\"].map(smoking_mapping)\n",
    "\n",
    "# Check the new value counts\n",
    "print(data[\"smoking_history\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all categorical variables to numeric using one-hot encoding\n",
    "data_encoded = pd.get_dummies(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Heatmap with the encoded data\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.heatmap(data_encoded.corr(), annot=True, cmap=\"magma\", fmt=\".2f\", linewidths=0.1)\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\n",
    "            \"num\",\n",
    "            StandardScaler(),\n",
    "            [\"age\", \"bmi\", \"blood_glucose_level\", \"hypertension\", \"heart_disease\"],\n",
    "        ),\n",
    "        (\n",
    "            \"cat\",\n",
    "            \"passthrough\",\n",
    "            [\n",
    "                \"gender_Female\",\n",
    "                \"gender_Male\",\n",
    "                \"smoking_history_current\",\n",
    "                \"smoking_history_non-smoker\",\n",
    "                \"smoking_history_past_smoker\",\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the variables X and y\n",
    "X = data_encoded.drop(\"hba1c_level\", axis=1)\n",
    "y = data_encoded[\"hba1c_level\"]\n",
    "\n",
    "# Remove the unnecessary features\n",
    "X = X.drop([\"diabetes\"], axis=1)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models with their best parameters\n",
    "models = {\n",
    "    \"Linear Regression\": {\n",
    "        \"model\": LinearRegression(fit_intercept=False),\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"model\": RandomForestRegressor(\n",
    "            n_estimators=100, min_samples_split=2, max_depth=5\n",
    "        ),\n",
    "        # \"max_depth\": [None, 5, 10],\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"model\": XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.1),\n",
    "    },\n",
    "    \"KNN\": {\n",
    "        \"model\": KNeighborsRegressor(weights=\"uniform\", n_neighbors=10),\n",
    "    },\n",
    "}\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results = pd.DataFrame(columns=[\"Model\", \"MSE\", \"MAE\", \"R2\"])\n",
    "\n",
    "# Train each model and calculate its MSE, MAE, and R2 score\n",
    "for name, model_info in models.items():\n",
    "    model = model_info[\"model\"]\n",
    "\n",
    "    # Create a pipeline with the preprocessor and the model\n",
    "    reg = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"regressor\", model),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Fit the model\n",
    "    reg.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = reg.predict(X_test)\n",
    "\n",
    "    # Calculate the metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    mse_scores = cross_val_score(\n",
    "        reg, X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\"\n",
    "    )\n",
    "    mae_scores = cross_val_score(\n",
    "        reg, X_train, y_train, cv=5, scoring=\"neg_mean_absolute_error\"\n",
    "    )\n",
    "    r2_scores = cross_val_score(reg, X_train, y_train, cv=5, scoring=\"r2\")\n",
    "\n",
    "    print(f\"Cross Validation for {name}: \")\n",
    "    print(f\"MSE: {-mse_scores.mean():.2f}\")\n",
    "    print(f\"MAE: {-mae_scores.mean():.2f}\")\n",
    "    print(f\"R2: {r2_scores.mean():.2f}\")\n",
    "    print()\n",
    "\n",
    "    # Append the results to the DataFrame\n",
    "    results.loc[len(results)] = [name, mse, mae, r2]\n",
    "\n",
    "    # Print the feature importances\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        print(f\"Feature importances for {name}:\")\n",
    "        for feature, importance in zip(X_train.columns, model.feature_importances_):\n",
    "            print(f\"{feature}: {importance}\")\n",
    "    else:\n",
    "        print(f\"Permutation importances for {name}:\")\n",
    "        X_test_preprocessed = reg.named_steps[\"preprocessor\"].transform(X_test)\n",
    "        r = permutation_importance(\n",
    "            model, X_test_preprocessed, y_test, n_repeats=15, random_state=0\n",
    "        )\n",
    "        for i in r.importances_mean.argsort()[::-1]:\n",
    "            if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "                print(f\"{X_test.columns[i]}: {r.importances_mean[i]:.3f}\")\n",
    "\n",
    "    print()\n",
    "\n",
    "# Print the results\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=\"Model\", y=\"R2\", data=results, palette=\"magma\")\n",
    "plt.title(\"Model R2 Score Comparison\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Train the Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the models and their respective hyperparameters\n",
    "# models = {\n",
    "#     \"Linear Regression\": {\n",
    "#         \"model\": LinearRegression(),\n",
    "#         \"params\": {\"fit_intercept\": [True, False]},\n",
    "#     },\n",
    "#     \"Random Forest\": {\n",
    "#         \"model\": RandomForestRegressor(random_state=42),\n",
    "#         \"params\": {\n",
    "#             \"n_estimators\": [10, 50, 100],\n",
    "#             \"max_depth\": [None, 5, 10],\n",
    "#             \"min_samples_split\": [2, 5, 10],\n",
    "#         },\n",
    "#     },\n",
    "#     \"SVR\": {\n",
    "#         \"model\": SVR(),\n",
    "#         \"params\": {\n",
    "#             \"C\": [0.1, 1, 10, 100],\n",
    "#             \"gamma\": [\"scale\", \"auto\"],\n",
    "#             \"kernel\": [\"linear\", \"rbf\"],\n",
    "#         },\n",
    "#     },\n",
    "#     \"XGBoost\": {\n",
    "#         \"model\": XGBRegressor(random_state=42),\n",
    "#         \"params\": {\n",
    "#             \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "#             \"max_depth\": [3, 5, 10],\n",
    "#             \"n_estimators\": [50, 100],\n",
    "#         },\n",
    "#     },\n",
    "#     \"KNN\": {\n",
    "#         \"model\": KNeighborsRegressor(),\n",
    "#         \"params\": {\n",
    "#             \"n_neighbors\": [3, 5, 10],\n",
    "#             \"weights\": [\"uniform\", \"distance\"],\n",
    "#             \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "#         },\n",
    "#     },\n",
    "# }\n",
    "\n",
    "# # Create a DataFrame to store the results\n",
    "# results = pd.DataFrame(columns=[\"Model\", \"Best Params\", \"MSE\", \"MAE\", \"R2\"])\n",
    "\n",
    "# # Train each model and calculate its MSE, MAE, and R2 score\n",
    "# for name, model in models.items():\n",
    "#     reg = Pipeline(\n",
    "#         steps=[\n",
    "#             (\"preprocessor\", preprocessor),\n",
    "#             (\n",
    "#                 \"regressor\",\n",
    "#                 RandomizedSearchCV(\n",
    "#                     model[\"model\"], model[\"params\"], n_iter=10, cv=3, n_jobs=-1\n",
    "#                 ),\n",
    "#             ),\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "#     reg.fit(X_train, y_train)\n",
    "\n",
    "#     y_pred = reg.predict(X_test)\n",
    "\n",
    "#     mse = mean_squared_error(y_test, y_pred)\n",
    "#     mae = mean_absolute_error(y_test, y_pred)\n",
    "#     r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "#     # Append the results to the DataFrame\n",
    "#     results.loc[len(results)] = [\n",
    "#         name,\n",
    "#         reg.named_steps[\"regressor\"].best_params_,\n",
    "#         mse,\n",
    "#         mae,\n",
    "#         r2,\n",
    "#     ]\n",
    "\n",
    "# # Plot the results\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# sns.barplot(x=\"Model\", y=\"R2\", data=results, palette=\"magma\")\n",
    "# plt.title(\"Model R2 Score Comparison\")\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conda-FYP-App",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
